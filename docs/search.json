[
  {
    "objectID": "examples/collect/data_processing/creating_a_user_gui.html",
    "href": "examples/collect/data_processing/creating_a_user_gui.html",
    "title": "2 Creating a user GUI",
    "section": "",
    "text": "Here we use the svDialogs package to popup a graphical user interface (GUI) which allows the user to specify variables for use later in a script. It checks to see what operating system the user is using and provides specific dialogs depending on the OS.\n\nprint(\"Checking Operating System:\")\n# Determine the operating system\nos_type &lt;- Sys.info()[\"sysname\"]\n\nif (os_type == \"Darwin\") {\n  print(\"Running macOS\")\n} else if (os_type == \"Windows\") {\n  print(\"Running Windows\")\n} else if (os_type == \"Linux\") {\n  print(\"Running Linux\")\n} else {\n  stop(\"Unsupported operating system: \", os_type)\n}\n\nsvDialogs::dlg_message(\"################################################### Next several popup dialogs will allow you to choose:_______________ 1: Directory containing 360 images__________________________________ 2: Minimum distance between images (metres)_____________________ 3: Add overlay to images (TRUE/FALSE)_____________________________ 4: Select an overlay image file (png)_________________________________ ###################################################\", rstudio = TRUE)$res\n\n # If on a mac popup a dialog telling the user what the select is for: Apple OS has no title text on select directory/file dialogs.... Who thought that was a good idea!\nif (os_type == \"Darwin\") {\n  svDialogs::dlg_message(\"Next: Select directory containing 360 images.\")\n}\n# Choose the directory path containing 360 images.\ndirectory &lt;- svDialogs::dlg_dir(default = getwd(), title = \"Select Directory Containing 360 images\")$res\n\n# Select the minimum distance in metres between each extracted image.\nmetresBetweenEachImageWanted &lt;- as.numeric(svDialogs::dlg_input(message = \"Enter a value for: metresBetweenEachImageWanted\", default = \"100\")$res)\n\n# Set to TRUE to add overlays to each image file; or FALSE to use images without any overlays.\n# Get user input for add overlays\naddOverlays_input &lt;- svDialogs::dlg_input(message = \"Add Overlays to images? (TRUE/FALSE)\", default = \"TRUE\")$res\nstr(addOverlays_input)\nif (!(is.character(addOverlays_input) && length(addOverlays_input) == 1 && addOverlays_input %in% c(\"TRUE\", \"FALSE\"))) {\n  stop(\"addOverlays_input must be a single character value, either 'TRUE' or 'FALSE'.\")\n} else {\n  addOverlays &lt;- if (tolower(addOverlays_input) %in% c(\"true\", \"yes\", \"1\")) {\n  TRUE\n} else if (tolower(addOverlays_input) %in% c(\"false\", \"no\", \"0\")) {\n  FALSE\n} else {\n  stop(\"Invalid input for 'addOverlays'. Please enter TRUE or FALSE.\")\n}\n}\n\n# Conditionally set the overlay image file if addOverlays is TRUE\nif (addOverlays == TRUE) {\n  # If on a mac popup a dialog telling the user what the select is for: Apple OS has no title text on select directory/file dialogs.... Who thought that was a good idea!\n  if (os_type == \"Darwin\") {\n  svDialogs::dlg_message(\"Next: Select overlay file (png)\")\n}\n  # Choose the file for your desired overlay image (PNG image with transparency).\n  overlayImageFile &lt;- svDialogs::dlg_open(default = \"./overlay_files\", title = \"Select overlay file (png)\", multiple = FALSE, filters = svDialogs::dlg_filters[\"png\", ])$res\n} else if (identical(addOverlays, FALSE) || length(addOverlays) == 0) {\n  overlayImageFile &lt;- NULL\n  }\n\nfinalMessage &lt;- paste0(\"######################################################## You have selected: Folder with 360 Images: \", directory,\n   \" Metres Between Each Image Wanted: \", metresBetweenEachImageWanted, \" AddOverlays: \", addOverlays)\nif (addOverlays == TRUE) {\n  finalMessage &lt;- paste0(finalMessage, \" Overlay Image File: \" , overlayImageFile)\n}\n\nsvDialogs::dlg_message(message = finalMessage, type = \"ok\")"
  },
  {
    "objectID": "examples/collect/data_processing/creating_a_user_gui.html#set-user-options-svdialogs-gui-version",
    "href": "examples/collect/data_processing/creating_a_user_gui.html#set-user-options-svdialogs-gui-version",
    "title": "2 Creating a user GUI",
    "section": "",
    "text": "Here we use the svDialogs package to popup a graphical user interface (GUI) which allows the user to specify variables for use later in a script. It checks to see what operating system the user is using and provides specific dialogs depending on the OS.\n\nprint(\"Checking Operating System:\")\n# Determine the operating system\nos_type &lt;- Sys.info()[\"sysname\"]\n\nif (os_type == \"Darwin\") {\n  print(\"Running macOS\")\n} else if (os_type == \"Windows\") {\n  print(\"Running Windows\")\n} else if (os_type == \"Linux\") {\n  print(\"Running Linux\")\n} else {\n  stop(\"Unsupported operating system: \", os_type)\n}\n\nsvDialogs::dlg_message(\"################################################### Next several popup dialogs will allow you to choose:_______________ 1: Directory containing 360 images__________________________________ 2: Minimum distance between images (metres)_____________________ 3: Add overlay to images (TRUE/FALSE)_____________________________ 4: Select an overlay image file (png)_________________________________ ###################################################\", rstudio = TRUE)$res\n\n # If on a mac popup a dialog telling the user what the select is for: Apple OS has no title text on select directory/file dialogs.... Who thought that was a good idea!\nif (os_type == \"Darwin\") {\n  svDialogs::dlg_message(\"Next: Select directory containing 360 images.\")\n}\n# Choose the directory path containing 360 images.\ndirectory &lt;- svDialogs::dlg_dir(default = getwd(), title = \"Select Directory Containing 360 images\")$res\n\n# Select the minimum distance in metres between each extracted image.\nmetresBetweenEachImageWanted &lt;- as.numeric(svDialogs::dlg_input(message = \"Enter a value for: metresBetweenEachImageWanted\", default = \"100\")$res)\n\n# Set to TRUE to add overlays to each image file; or FALSE to use images without any overlays.\n# Get user input for add overlays\naddOverlays_input &lt;- svDialogs::dlg_input(message = \"Add Overlays to images? (TRUE/FALSE)\", default = \"TRUE\")$res\nstr(addOverlays_input)\nif (!(is.character(addOverlays_input) && length(addOverlays_input) == 1 && addOverlays_input %in% c(\"TRUE\", \"FALSE\"))) {\n  stop(\"addOverlays_input must be a single character value, either 'TRUE' or 'FALSE'.\")\n} else {\n  addOverlays &lt;- if (tolower(addOverlays_input) %in% c(\"true\", \"yes\", \"1\")) {\n  TRUE\n} else if (tolower(addOverlays_input) %in% c(\"false\", \"no\", \"0\")) {\n  FALSE\n} else {\n  stop(\"Invalid input for 'addOverlays'. Please enter TRUE or FALSE.\")\n}\n}\n\n# Conditionally set the overlay image file if addOverlays is TRUE\nif (addOverlays == TRUE) {\n  # If on a mac popup a dialog telling the user what the select is for: Apple OS has no title text on select directory/file dialogs.... Who thought that was a good idea!\n  if (os_type == \"Darwin\") {\n  svDialogs::dlg_message(\"Next: Select overlay file (png)\")\n}\n  # Choose the file for your desired overlay image (PNG image with transparency).\n  overlayImageFile &lt;- svDialogs::dlg_open(default = \"./overlay_files\", title = \"Select overlay file (png)\", multiple = FALSE, filters = svDialogs::dlg_filters[\"png\", ])$res\n} else if (identical(addOverlays, FALSE) || length(addOverlays) == 0) {\n  overlayImageFile &lt;- NULL\n  }\n\nfinalMessage &lt;- paste0(\"######################################################## You have selected: Folder with 360 Images: \", directory,\n   \" Metres Between Each Image Wanted: \", metresBetweenEachImageWanted, \" AddOverlays: \", addOverlays)\nif (addOverlays == TRUE) {\n  finalMessage &lt;- paste0(finalMessage, \" Overlay Image File: \" , overlayImageFile)\n}\n\nsvDialogs::dlg_message(message = finalMessage, type = \"ok\")"
  },
  {
    "objectID": "examples/collect/data_processing/creating_a_user_gui.html#function-to-check-that-user-options-are-set",
    "href": "examples/collect/data_processing/creating_a_user_gui.html#function-to-check-that-user-options-are-set",
    "title": "2 Creating a user GUI",
    "section": "Function to Check that User Options Are Set",
    "text": "Function to Check that User Options Are Set\nHere we write a function to test that user options exist so we can inform the user if the options are not set.\n\n# This code checks to see the user options exist for further code chunks.\n checkUserOptionsExist &lt;- function(directory = NULL, metresBetweenEachImageWanted = NULL, addOverlays = NULL, overlayImageFile = NULL) {\n  print(\"Checking that all user options have been set:\") \n  # Check if 'directory' is provided and is a valid folder path\n  if (is.null(directory) || !is.character(directory) || nchar(directory) == 0 || !dir.exists(directory)) {\n    stop(\"'directory' must be a valid folder path containing the GoPro images. \\n Have you run the code chunk under 'Set User Options' with a valid directory containing images?\")\n  }\n  \n  # Check if 'metresBetweenEachImageWanted' is provided and is a positive numeric value\n  if (is.null(metresBetweenEachImageWanted) || !is.numeric(metresBetweenEachImageWanted) || metresBetweenEachImageWanted &lt;= 0) {\n    stop(\"'metresBetweenEachImageWanted' must be a positive numeric value.\\n Have you run the code chunk under 'Set User Options'?\")\n  }\n  \n  # Check if 'addOverlays' is provided and is either TRUE or FALSE\n  if (is.null(addOverlays) || !is.logical(addOverlays) || length(addOverlays) != 1) {\n    stop(\"'addOverlays' must be either TRUE or FALSE.\\n Have you run the code chunk under 'Set User Options'?\")\n  }\n  \n  # Check if 'overlayImageFile' is provided and valid if 'addOverlays' is TRUE\n  if (addOverlays) {\n    if (is.null(overlayImageFile) || !is.character(overlayImageFile) || nchar(overlayImageFile) == 0 || !file.exists(overlayImageFile)) {\n      stop(\"'overlayImageFile' must be a valid file path when 'addOverlays' is TRUE.\\n Have you run the code chunk under 'Set User Options'?\")\n    }\n  }\n  \n  # If all checks pass, return TRUE\n  return(TRUE)\n}"
  },
  {
    "objectID": "examples/collect/data_processing/creating_a_user_gui.html#call-the-function",
    "href": "examples/collect/data_processing/creating_a_user_gui.html#call-the-function",
    "title": "2 Creating a user GUI",
    "section": "Call the function",
    "text": "Call the function\nNext we call the function and if all parameters are set it will return TRUE.\n\n# Check if 'Set User Options' has been run and throw an error if not\ncheckUserOptionsExist(directory, metresBetweenEachImageWanted, addOverlays, overlayImageFile)"
  },
  {
    "objectID": "examples/collect/data_processing/distance_between_images.html",
    "href": "examples/collect/data_processing/distance_between_images.html",
    "title": "4 Distance between images",
    "section": "",
    "text": "This code looks through all the geocoded jpeg files in a given folder and copies images a user-specified distance apart into a new folder for use later on. It starts with the first file and looks for a file at least XX metres from that. Once it finds one it adds it to the list then uses it as the location to look for another file at least XX metres from it and so on until it gets to the end of the file list. This method is most suitable for linear transect sampling but should work with any images that are spaced out enough.\n\nlibrary(geosphere)\n\noptions(digits = 20)\noptions(digits.secs = 20)\noptions(scipen = 9999)\n\n#function which takes 2 arguments\n#1:gpx_locations - a dataframe containing 4 columns(\"SourceFile\", \"System:Directory\", \"Composite:GPSLongitude\", \"Composite:GPSLatitude\")\n#2:distance in metres between each image to extract. (default=20m)\nfindImagesEveryXmetres &lt;-\n  function(my_gpx_locs, metresToNextImage = 20) {\n    gpx_locs &lt;- my_gpx_locs\n    \n    keeps &lt;- c(\"Composite:GPSLongitude\", \"Composite:GPSLatitude\")\n    points &lt;- gpx_locs[keeps]\n    \n    #View(points)\n    #View(gpx_locs)\n    \n    #calculate the distance between any two points\n    distance_m &lt;- geosphere::distm(points , fun = geosphere::distHaversine)\n    rownames(distance_m) &lt;- basename(gpx_locs[, \"SourceFile\"])\n    colnames(distance_m) &lt;- basename(gpx_locs[, \"SourceFile\"])\n    \n    #View(distance_m)\n    \n    #find images a certain distance apart.\n    selected_files &lt;- vector()\n    \n    metres_between_images &lt;- metresToNextImage\n    \n    print(paste0(\n      \"Searching for images apart by: \",\n      metres_between_images,\n      \" metres\"\n    ))\n    \n    for (i in 1:nrow(distance_m)) {\n      if (i == 1) {\n        #if it is the first frame add it as the current frame\n        selected_files &lt;-\n          append(selected_files, rownames(distance_m)[i])\n        current_frame &lt;- rownames(distance_m)[i]\n        print(paste0(\"Frame 1: \", current_frame))\n        print(paste0(\n          \"looking for frame &gt;\",\n          metres_between_images ,\n          \" Metres from frame 1\"\n        ))\n      }#if the current frame is greater than the specified metres\n      if (distance_m[i, current_frame] &gt; as.numeric(metres_between_images)) {\n        current_frame &lt;- rownames(distance_m)[i]\n        print(paste0(\"current_frame: \", current_frame))\n        selected_files &lt;- append(selected_files, current_frame)\n      }\n      \n    }\n    print(paste0(\"Files found:\", selected_files))\n    \n    new_folder &lt;-\n      paste0(gpx_locs[1, \"System:Directory\"], \"_\", metres_between_images, \"m_apart\")\n    \n    dir.create(new_folder)\n    \n    source_folder &lt;-  dirname(gpx_locs[1, \"SourceFile\"])\n    \n    print(gpx_locs[1, \"System:Directory\"])\n    \n    for (q in selected_files) {\n      file_to_copy &lt;- paste0(source_folder, \"/\", q)\n      destination &lt;- paste0(new_folder,  \"/\", q)\n      file.copy(\n        file_to_copy,\n        destination,\n        overwrite = TRUE,\n        recursive = FALSE,\n        copy.mode = TRUE,\n        copy.date = TRUE\n      )\n    }\n    \n  }\n\nprint(\"findImagesEveryXmetres(my_gpx_locs, metresToNextImage) function is now available to call\")"
  },
  {
    "objectID": "examples/collect/data_processing/distance_between_images.html#function-to-calculate-distances-between-image-geo-locations.",
    "href": "examples/collect/data_processing/distance_between_images.html#function-to-calculate-distances-between-image-geo-locations.",
    "title": "4 Distance between images",
    "section": "",
    "text": "This code looks through all the geocoded jpeg files in a given folder and copies images a user-specified distance apart into a new folder for use later on. It starts with the first file and looks for a file at least XX metres from that. Once it finds one it adds it to the list then uses it as the location to look for another file at least XX metres from it and so on until it gets to the end of the file list. This method is most suitable for linear transect sampling but should work with any images that are spaced out enough.\n\nlibrary(geosphere)\n\noptions(digits = 20)\noptions(digits.secs = 20)\noptions(scipen = 9999)\n\n#function which takes 2 arguments\n#1:gpx_locations - a dataframe containing 4 columns(\"SourceFile\", \"System:Directory\", \"Composite:GPSLongitude\", \"Composite:GPSLatitude\")\n#2:distance in metres between each image to extract. (default=20m)\nfindImagesEveryXmetres &lt;-\n  function(my_gpx_locs, metresToNextImage = 20) {\n    gpx_locs &lt;- my_gpx_locs\n    \n    keeps &lt;- c(\"Composite:GPSLongitude\", \"Composite:GPSLatitude\")\n    points &lt;- gpx_locs[keeps]\n    \n    #View(points)\n    #View(gpx_locs)\n    \n    #calculate the distance between any two points\n    distance_m &lt;- geosphere::distm(points , fun = geosphere::distHaversine)\n    rownames(distance_m) &lt;- basename(gpx_locs[, \"SourceFile\"])\n    colnames(distance_m) &lt;- basename(gpx_locs[, \"SourceFile\"])\n    \n    #View(distance_m)\n    \n    #find images a certain distance apart.\n    selected_files &lt;- vector()\n    \n    metres_between_images &lt;- metresToNextImage\n    \n    print(paste0(\n      \"Searching for images apart by: \",\n      metres_between_images,\n      \" metres\"\n    ))\n    \n    for (i in 1:nrow(distance_m)) {\n      if (i == 1) {\n        #if it is the first frame add it as the current frame\n        selected_files &lt;-\n          append(selected_files, rownames(distance_m)[i])\n        current_frame &lt;- rownames(distance_m)[i]\n        print(paste0(\"Frame 1: \", current_frame))\n        print(paste0(\n          \"looking for frame &gt;\",\n          metres_between_images ,\n          \" Metres from frame 1\"\n        ))\n      }#if the current frame is greater than the specified metres\n      if (distance_m[i, current_frame] &gt; as.numeric(metres_between_images)) {\n        current_frame &lt;- rownames(distance_m)[i]\n        print(paste0(\"current_frame: \", current_frame))\n        selected_files &lt;- append(selected_files, current_frame)\n      }\n      \n    }\n    print(paste0(\"Files found:\", selected_files))\n    \n    new_folder &lt;-\n      paste0(gpx_locs[1, \"System:Directory\"], \"_\", metres_between_images, \"m_apart\")\n    \n    dir.create(new_folder)\n    \n    source_folder &lt;-  dirname(gpx_locs[1, \"SourceFile\"])\n    \n    print(gpx_locs[1, \"System:Directory\"])\n    \n    for (q in selected_files) {\n      file_to_copy &lt;- paste0(source_folder, \"/\", q)\n      destination &lt;- paste0(new_folder,  \"/\", q)\n      file.copy(\n        file_to_copy,\n        destination,\n        overwrite = TRUE,\n        recursive = FALSE,\n        copy.mode = TRUE,\n        copy.date = TRUE\n      )\n    }\n    \n  }\n\nprint(\"findImagesEveryXmetres(my_gpx_locs, metresToNextImage) function is now available to call\")"
  },
  {
    "objectID": "examples/collect/data_processing/distance_between_images.html#call-function-above",
    "href": "examples/collect/data_processing/distance_between_images.html#call-function-above",
    "title": "4 Distance between images",
    "section": "Call Function Above",
    "text": "Call Function Above\nNow call the function above to calculate the distance between all the images and copy them to a new folder.\n\nlibrary(exiftoolr)\n\n# you will need to edit the directory that contains the .jpg files to rename.\ndirectory &lt;- \"c:/path_to_the_directory_with_files_to_rename\"\n\n# set the metres between each image\nmetresBetweenEachImageWanted &lt;- 50\n\n# filter only .jpg or .JPG files\nfile_extension &lt;- \"\\\\.[Jj][Pp][Gg]$\"\n\nmy_files &lt;-\n  list.files(\n    normalizePath(directory, winslash = \"/\"),\n    pattern = paste0(file_extension),\n    all.files = FALSE,\n    full.names = TRUE\n  )\n\nimage_files_df &lt;-\n  exiftoolr::exif_read(my_files, args = c(\"-G1\", \"-a\", \"-s\"))\n\n#View(image_files_df)\n\ngpx_locs &lt;-\n  as.data.frame(image_files_df[, c(\n    \"SourceFile\",\n    \"System:Directory\",\n    \"Composite:GPSLatitude\",\n    \"Composite:GPSLongitude\"\n  )])\n\n#View(gpx_locs)\n\nif (!exists(\"metresBetweenEachImageWanted\") || length(metresBetweenEachImageWanted) == 0) {\n  print(\"'metresBetweenEachImageWanted' does not exist. Using Default value. Please run the code chunk under 'Set User Options' above if you want to change the metresBetweenEachImageWanted\")\n  findImagesEveryXmetres(my_gpx_locs = gpx_locs)\n} else {\n  findImagesEveryXmetres(my_gpx_locs = gpx_locs, metresToNextImage = metresBetweenEachImageWanted)\n}"
  },
  {
    "objectID": "examples/collect/data_processing/check_install_packages.html",
    "href": "examples/collect/data_processing/check_install_packages.html",
    "title": "1 Check & install packages",
    "section": "",
    "text": "The code below loops over a list of libraries and checks if they are installed. If not, it installs them.\n\ndependentPackages &lt;-\n  c(\"svDialogs\",\n    \"tools\",\n    \"exiftoolr\",\n    \"geosphere\",\n    \"stringr\",\n    \"gpx\",\n    \"magick\",\n    \"imager\",\n    \"abind\",\n    \"fs\",\n    \"magrittr\",\n    \"zip\",\n    \"usefun\"\n  )\n\nfor (i in dependentPackages) {\n  print(paste0(\"Checking for: \", i))\n  \n  # First check if you have the package installed\n  check_for_package &lt;- system.file(package = i)\n  print(check_for_package)\n  \n  # If not run the following code to install it.\n  if (check_for_package == \"\") {\n    print(paste0(i, \" package not found .....installing now\"))\n    install.packages(i)\n  } else {\n    print(paste0(i, \" package is already installed\"))\n  }\n}"
  },
  {
    "objectID": "why.html",
    "href": "why.html",
    "title": "Why",
    "section": "",
    "text": "Field surveys have always been expensive and time consuming, so ecologists and other research professionals have struggled to collect field data on environmental processes that operate at landscape scales. In this era of global change, integrative, multi-scale research and landscape-level mapping is only increasing in importance. Modern 360-degree cameras and the pannotator package provide a way forward.\n\n\nDocumenting how environmental processes impact ecosystems involves collecting large amounts of data on individuals that can then be scaled up to entire communities.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraditionally, field surveys have been done by visually scoring environmental variables, recording the data (usually on paper) and manually translating GPS coordinates. This has created what‚Äôs known as ‚Äòthe scaling problem.‚Äô But 360-degree cameras now allow us to rapidly collect images that provide a permanent record of all of these features and more.",
    "crumbs": [
      "Why"
    ]
  },
  {
    "objectID": "index.html#join-the-future-of-scientific-data-collection",
    "href": "index.html#join-the-future-of-scientific-data-collection",
    "title": "Scientific Data Collection with 360¬∞ Cameras",
    "section": "Join the Future of Scientific Data Collection",
    "text": "Join the Future of Scientific Data Collection\nData collection is one of the most time-consuming and labour-intensive tasks in field based research. Pannotator is an new software package designed to streamline and accelerate the process by using modern 360¬∞ camera technology. Our workflow enables researchers to efficiently capture and analyze vast amounts of environmental, ecological, and other field-based data ‚Äî all in a fraction of the time compared to traditional methods.",
    "crumbs": [
      "Why",
      "Pannotator"
    ]
  },
  {
    "objectID": "index.html#advantages-of-360-cameras",
    "href": "index.html#advantages-of-360-cameras",
    "title": "Scientific Data Collection with 360¬∞ Cameras",
    "section": "Advantages of 360¬∞ Cameras",
    "text": "Advantages of 360¬∞ Cameras\nConventional cameras limit your perspective to a single angle at a time. 360¬∞ cameras eliminate this constraint, capturing a complete panoramic view of the environment in every frame. This means:\n‚úÖ Faster data collection ‚Äì Record entire scenes in one shot instead of taking multiple images.\n‚úÖ Increased accuracy ‚Äì Reduce the risk of missing important details by capturing multiple perspectives.\n‚úÖ Permanent record - Data collected is a snapshot in time and space, with GPS enabled cameras, the site can be revisited at a later date.\n‚úÖ Cheap and robust - Modern cameras are durable, robust, small, light and relatively cheap.",
    "crumbs": [
      "Why",
      "Pannotator"
    ]
  },
  {
    "objectID": "index.html#key-features-of-the-pannotator-package",
    "href": "index.html#key-features-of-the-pannotator-package",
    "title": "Scientific Data Collection with 360¬∞ Cameras",
    "section": "Key Features of the pannotator package",
    "text": "Key Features of the pannotator package\n‚úÖ Open Source - Every part of the workflow is open source so you are in the drivers seat and control every step.\n‚úÖ User-Friendly Interface ‚Äì Designed to have an intuitive workflow.\n‚úÖ Fully Customizable ‚Äì Allows annotation of 360-degree images and satellite data for precise mapping and modelling.\n‚úÖ Immersive Experience ‚Äì Seamless visualisation of multiple data sources.",
    "crumbs": [
      "Why",
      "Pannotator"
    ]
  },
  {
    "objectID": "index.html#who-is-this-for",
    "href": "index.html#who-is-this-for",
    "title": "Scientific Data Collection with 360¬∞ Cameras",
    "section": "Who is This For?",
    "text": "Who is This For?\nüî¨ Ecologists & Environmental Scientists ‚Äì Monitor habitats, track biodiversity, and assess environmental change.\nüèó Engineers & Surveyors ‚Äì Conduct structural inspections and site assessments.\nüåç Geologists & Archaeologists ‚Äì Capture and analyze geological formations or historical sites without disturbing the area.\nü¶∫ Conservationists & Park Managers ‚Äì Monitor park ecosystems, assess habitat conditions, and track wildlife behaviours with consistent, repeatable observations.\nüöÄ Download pannotator and get started today!",
    "crumbs": [
      "Why",
      "Pannotator"
    ]
  },
  {
    "objectID": "examples/collect/index.html",
    "href": "examples/collect/index.html",
    "title": "Pannotator",
    "section": "",
    "text": "Once you have collected your data in the field, the next steps involve processing it to prepare for annotation.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Data processing"
    ]
  },
  {
    "objectID": "examples/collect/index.html#getting-started",
    "href": "examples/collect/index.html#getting-started",
    "title": "Pannotator",
    "section": "Getting Started",
    "text": "Getting Started\nThe scripts on this site are quarto documents which can be easily edited in VS Code or RStudio.\nYou can get the latest version of RStudio here.\nIf you are new to quarto and want to find out about it, check out this quarto tutorial.\nBelow we provide step by step examples of the workflow with code for processing your data. You can access complete scripts in the pannotator collect GitHub repository.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Data processing"
    ]
  },
  {
    "objectID": "examples/collect/index.html#data-processing",
    "href": "examples/collect/index.html#data-processing",
    "title": "Pannotator",
    "section": "Data processing",
    "text": "Data processing\nHere we break down the common data processing steps into single scripts so you can see each step separately.\n\n\n\n\n\n\n\n\n\n\n1 Check & install packages\n\n\n1 min\n\n\n\nInstall R packages\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2 Creating a user GUI\n\n\n4 min\n\n\n\nUser Parameters\n\n\nGUI\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3 Renaming files\n\n\n3 min\n\n\n\nFile Management\n\n\nRename Files\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 Distance between images\n\n\n5 min\n\n\n\nSpatial Calculations\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n5 Add overlays to images\n\n\n3 min\n\n\n\nImage manipulation\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Data processing"
    ]
  },
  {
    "objectID": "examples/collect/index.html#generate-kmz",
    "href": "examples/collect/index.html#generate-kmz",
    "title": "Pannotator",
    "section": "Generate kmz",
    "text": "Generate kmz\nHere is the example code to generate google earth files (kml/kmz) only\n\n\n\n\n\n\n\n\n\n\n6 Create google earth files\n\n\n5 min\n\n\n\nFile Management\n\n\nGoogle Earth\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Data processing"
    ]
  },
  {
    "objectID": "examples/collect/index.html#complete-workflow-scripts",
    "href": "examples/collect/index.html#complete-workflow-scripts",
    "title": "Pannotator",
    "section": "Complete workflow scripts",
    "text": "Complete workflow scripts\nHere we put it all together and provide end to end scripts for you to generate files ready to load into pannotator and get annotating.\n\n\n\n\n\n\n\n\n\n\n1 jpegs to kmz\n\n\n1 min\n\n\n\nFile Management\n\n\nGoogle Earth\n\n\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Data processing"
    ]
  },
  {
    "objectID": "examples/annotate/index.html",
    "href": "examples/annotate/index.html",
    "title": "Annotate Examples",
    "section": "",
    "text": "Install pannotator\n\n\nThis example shows you how install pannotator.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "collect_overview.html",
    "href": "collect_overview.html",
    "title": "Collect",
    "section": "",
    "text": "Unpacking image collection and preparation for the pannotator package",
    "crumbs": [
      "Why",
      "How",
      "Collect"
    ]
  },
  {
    "objectID": "collect_kandao_qoocam3ultra.html",
    "href": "collect_kandao_qoocam3ultra.html",
    "title": "Qoocam 3 Ultra",
    "section": "",
    "text": "The Kandao Qoocam 3 Ultra looks like it will be a good option for our workflow, it can take 96 megapixel images!\nCheck back here to find information about this camera when we can get hold of one.\nIf suitable we will add scripts to include it in our workflow.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Field Collection",
      "Kandao Qoocam 3 Ultra"
    ]
  },
  {
    "objectID": "collect_gopro_max.html",
    "href": "collect_gopro_max.html",
    "title": "GoPro Max",
    "section": "",
    "text": "The GoPro Max was the original camera we used to develop this workflow and it worked well in the harsh Australian outback. The GoPro Max has an integrated GPS which makes collecting geolocated images and video possible. This simplifies the setup needed to collect data. We have produced scripts enabling anyone to use still images and videos from the GoPro Max.\n\nYou can find the scripts needed to use this camera here.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Field Collection",
      "Gopro Max"
    ]
  },
  {
    "objectID": "collect_drones.html",
    "href": "collect_drones.html",
    "title": "Drones",
    "section": "",
    "text": "Most consumer drones are capable of taking 360-degree images by stitching multiple images taken from different angles into one large equirectangular image. These images have the advantage of being much higher resolution than those taken with a dedicated 360 camera, although they take a little longer to collect and may not be suitable for moving objects. They have the advantage of enabling data capture at the canopy level, a more challenging task using conventional 360 cameras. Here is a video showing you how to take 360 pano images using a DJI drone and here is where you can find one: DJI mini 4 pro\n\nYou can find the scripts needed to use drone 360 pano images here.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Field Collection",
      "Drones"
    ]
  },
  {
    "objectID": "annotate_pannotator_vignette.html",
    "href": "annotate_pannotator_vignette.html",
    "title": "Pannotator vignette",
    "section": "",
    "text": "&lt;/p&gt;",
    "crumbs": [
      "Why",
      "How",
      "Annotate",
      "Pannotator vignette"
    ]
  },
  {
    "objectID": "analyse.html",
    "href": "analyse.html",
    "title": "Analyse",
    "section": "",
    "text": "Now that you have annotated your images and exported the data you are ready to analyse",
    "crumbs": [
      "Why",
      "How",
      "Analyse"
    ]
  },
  {
    "objectID": "about_nunz.html",
    "href": "about_nunz.html",
    "title": "Nunzio Knerr",
    "section": "",
    "text": "Working at Australia‚Äôs Commonwealth Scientific and Industrial Research Organisation (CSIRO) since 2009, Nunzio‚Äôs research bridges cutting‚Äêedge computational methods with field‚Äêbased research to understand plant diversity, distribution, and evolution. From investigating grassland community dynamics in the tropical floodplain ecosystems of Kakadu during the 1990s to more recently conducting field work in Uluru and far North Queensland in the 2020s. Nunzio has many years of practical research experience.\nNunzio has collaborated on many large‚Äêscale studies of Australian flora, helping to map bioregions, uncover patterns of phylogenetic endemism, and assess the impacts of invasive species. Publications on groups such as Asteraceae, Acacia, Eucalyptus, Banksia, and various invasive weeds underscore his commitment to safeguarding native ecosystems under threats of climate change and habitat loss.\nNunzio‚Äôs work often integrates ‚Äúbig data‚Äù approaches, from herbarium records to genomics, providing insights that inform biodiversity conservation at national and global scales. More recently Nunzio has developed advanced coding and software solutions for environmental monitoring, measurement and analysis.\nYou can see published articles here: Google Scholar Profile\nEmail: Nunzio.Knerr@csiro.au",
    "crumbs": [
      "Why",
      "About",
      "Nunzio Knerr"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Research Interests:\nWorking at Australia‚Äôs Commonwealth Scientific and Industrial Research Organisation (CSIRO) since 2009, Nunzio‚Äôs research bridges cutting‚Äêedge computational methods with field‚Äêbased research to understand plant diversity, distribution, and evolution. From investigating grassland community dynamics in the tropical floodplain ecosystems of Kakadu during the 1990s to more recently conducting field work in Uluru and far North Queensland in the 2020s. Nunzio has many years of practical research experience. More recently Nunzio has developed advanced coding and software solutions for environmental monitoring, measurement and analysis.",
    "crumbs": [
      "Why",
      "About"
    ]
  },
  {
    "objectID": "about.html#nunzio-knerr",
    "href": "about.html#nunzio-knerr",
    "title": "About",
    "section": "",
    "text": "Research Interests:\nWorking at Australia‚Äôs Commonwealth Scientific and Industrial Research Organisation (CSIRO) since 2009, Nunzio‚Äôs research bridges cutting‚Äêedge computational methods with field‚Äêbased research to understand plant diversity, distribution, and evolution. From investigating grassland community dynamics in the tropical floodplain ecosystems of Kakadu during the 1990s to more recently conducting field work in Uluru and far North Queensland in the 2020s. Nunzio has many years of practical research experience. More recently Nunzio has developed advanced coding and software solutions for environmental monitoring, measurement and analysis.",
    "crumbs": [
      "Why",
      "About"
    ]
  },
  {
    "objectID": "about.html#robert-godfree",
    "href": "about.html#robert-godfree",
    "title": "About",
    "section": "Robert Godfree",
    "text": "Robert Godfree\n\n\n\n\n\nResearch Interests:\nRobert Godfree is an Senior Research Scientist at Australia‚Äôs Commonwealth Scientific and Industrial Research Organisation (CSIRO). His current research focuses on measuring and predicting the impact of drought and heatwaves on biodiversity of natural and agricultural ecosystems and on developing new strategies for monitoring environmental change and health. His broader scientific portfolio includes both theoretical and applied approaches to biogeography, environmental change, fire ecology, evolutionary biology, restoration, invasive species, seed bank dynamics, soil fertility and water, plant physiology, polyploidy, competition and population dynamics. He has worked in forest, woodland, grassland, wetland, floodplain and arid ecosystems across Australia and in the USA.",
    "crumbs": [
      "Why",
      "About"
    ]
  },
  {
    "objectID": "about_bob.html",
    "href": "about_bob.html",
    "title": "Robert Godfree",
    "section": "",
    "text": "Robert Godfree is an Senior Research Scientist at Australia‚Äôs Commonwealth Scientific and Industrial Research Organisation (CSIRO). His current research focuses on measuring and predicting the impact of drought and heatwaves on biodiversity of natural and agricultural ecosystems and on developing new strategies for monitoring environmental change and health. His broader scientific portfolio includes both theoretical and applied approaches to biogeography, environmental change, fire ecology, evolutionary biology, restoration, invasive species, seed bank dynamics, soil fertility and water, plant physiology, polyploidy, competition and population dynamics. He has worked in forest, woodland, grassland, wetland, floodplain and arid ecosystems across Australia and in the USA.\nRecently, he published a book Drought Country which provides a deep dive into the history of drought in Australia over the past three centuries. The book focuses on how recurring cycles of drought have impacted the environmental and cultural landscape of Australia, beginning in the pre-European era and ending in the 2019-2020 ‚ÄúBlack Summer‚Äô.\nYou can find it here: Drought Country and published articles here: Google Scholar Profile\nEmail: Robert.Godfree@csiro.au",
    "crumbs": [
      "Why",
      "About",
      "Robert Godfree"
    ]
  },
  {
    "objectID": "acknowledgement.html",
    "href": "acknowledgement.html",
    "title": "Acknowledgement",
    "section": "",
    "text": "We thank Harriet Rhodes & Natalie Cooper, the handling editor Lorna Hernandez-Santin and the anonymous reviewers who did a fantastic job making suggestions to improve our paper and the pannotator package.",
    "crumbs": [
      "Why",
      "Acknowledgement"
    ]
  },
  {
    "objectID": "acknowledgement.html#methods-in-ecology-and-evolution-team",
    "href": "acknowledgement.html#methods-in-ecology-and-evolution-team",
    "title": "Acknowledgement",
    "section": "",
    "text": "We thank Harriet Rhodes & Natalie Cooper, the handling editor Lorna Hernandez-Santin and the anonymous reviewers who did a fantastic job making suggestions to improve our paper and the pannotator package.",
    "crumbs": [
      "Why",
      "Acknowledgement"
    ]
  },
  {
    "objectID": "acknowledgement.html#collaborators",
    "href": "acknowledgement.html#collaborators",
    "title": "Acknowledgement",
    "section": "Collaborators",
    "text": "Collaborators\n\n\nWe thank Nicholas Macgregor, Malcolm Coulthard (Nyukuti), Michael Cullinen (Tjapiya), Margarita Goumas, Tracey Guest, Sam Merson and Alyssa Roggero from Parks Australia for assistance with collecting data and/or organising logistical field support.\nThe A·πâangu community at Ulu·πüu-Kata Tju·πØa National Park generously provided access to their traditional lands and information on regional ecology and cultural history.",
    "crumbs": [
      "Why",
      "Acknowledgement"
    ]
  },
  {
    "objectID": "annotate.html",
    "href": "annotate.html",
    "title": "Annotate",
    "section": "",
    "text": "Now you are ready to start annotating",
    "crumbs": [
      "Why",
      "How",
      "Annotate"
    ]
  },
  {
    "objectID": "collaborate.html",
    "href": "collaborate.html",
    "title": "Collaborate",
    "section": "",
    "text": "We are keen to collaborate with other innovative people interested in using this technology.\nIf you want to reach out and have a project in mind we would love to hear from you.\nCollaborate\n\n\n\n\n\nMapping drought in Uluru-Kata Tjuta NP\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeed detection in far north Queensland\n\n\n\n\n\n\n\n\n\nHigh resolution vegetation mapping"
  },
  {
    "objectID": "collect_accessories.html",
    "href": "collect_accessories.html",
    "title": "Accessories",
    "section": "",
    "text": "When collecting ecological data using 360-degree cameras you will need some accessories. Here we outline those that we think are most essential to have in your kit.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Field Collection",
      "Accessories"
    ]
  },
  {
    "objectID": "collect_accessories.html#powerbank",
    "href": "collect_accessories.html#powerbank",
    "title": "Accessories",
    "section": "Powerbank",
    "text": "Powerbank\n\n\nYou can use a powerbank to avoid the need to change batteries when collection footage over long periods of time. In hot environments the camera can run on the powerbank alone and you can remove the inbuilt battery to avoid it overheating.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Field Collection",
      "Accessories"
    ]
  },
  {
    "objectID": "collect_accessories.html#long-cable",
    "href": "collect_accessories.html#long-cable",
    "title": "Accessories",
    "section": "Long Cable",
    "text": "Long Cable\n\n\n\n\n\n\n\n\n\nA long cable allows you to put the powerbank in a pocket or backpack to power your camera even when mounted on a selfie stick.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Field Collection",
      "Accessories"
    ]
  },
  {
    "objectID": "collect_accessories.html#selfie-stick",
    "href": "collect_accessories.html#selfie-stick",
    "title": "Accessories",
    "section": "Selfie Stick",
    "text": "Selfie Stick\n\n\nExtend your 360 camera above dense vegetation or into hard-to-reach spots using a selfie stick. Commercially available options can extend to 3 metres or longer.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Field Collection",
      "Accessories"
    ]
  },
  {
    "objectID": "collect_accessories.html#backpack",
    "href": "collect_accessories.html#backpack",
    "title": "Accessories",
    "section": "Backpack",
    "text": "Backpack\n\n\n\n\n\n\n\n\n\nYou can get a backpack that features a dedicated opening at the top, capable of accommodating your selfie stick. This setup allows you to position your 360 camera above the bag, leaving your hands free.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Field Collection",
      "Accessories"
    ]
  },
  {
    "objectID": "collect_accessories.html#reference-scale-objects",
    "href": "collect_accessories.html#reference-scale-objects",
    "title": "Accessories",
    "section": "Reference Scale Objects",
    "text": "Reference Scale Objects\n\n\nYou can use a rope with knots tied at specified intervals and a pole with similar marks that are visible in the collected images.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Field Collection",
      "Accessories"
    ]
  },
  {
    "objectID": "collect_field_collection.html",
    "href": "collect_field_collection.html",
    "title": "Field Collection",
    "section": "",
    "text": "Once your survey design is complete, the next step is to collect data in the field.\nDeciding on which camera equipment to use is important. There are a variety of 360-degree cameras on the market; here are a few options:\nOnce you have your field collection equipment, it‚Äôs a good idea to establish a protocol so that your data is collected in a consistent way.\nThe checklist below covers the main considerations.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Field Collection"
    ]
  },
  {
    "objectID": "collect_field_collection.html#pre-field-preparation",
    "href": "collect_field_collection.html#pre-field-preparation",
    "title": "Field Collection",
    "section": "1. Pre-Field Preparation",
    "text": "1. Pre-Field Preparation\n‚úÖ Charge all camera batteries and carry extras.\n‚úÖ Format memory cards and ensure adequate storage space.\n‚úÖ Install smartphone app for controlling the camera remotely.\n\nThese cameras have dedicated mobile apps that can control the cameras remotely.\nGopro quik\nInsta 360 X4",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Field Collection"
    ]
  },
  {
    "objectID": "collect_field_collection.html#image-capture-protocol-in-the-field",
    "href": "collect_field_collection.html#image-capture-protocol-in-the-field",
    "title": "Field Collection",
    "section": "2. Image Capture Protocol in the Field",
    "text": "2. Image Capture Protocol in the Field\n‚úÖ Verify that the camera lens covers are installed, clean and free of dust or moisture.\n‚úÖ Open smartphone app for controlling the camera remotely, or turn on camera manually.\n‚úÖ Set camera date/time & ensure GPS is setting is on.\n‚úÖ Verify camera capture settings:\n\nCapture type: Video/Images\n\nDepending on capture type, you will have different options to choose from:\n\nVideo type: eg. GoPro Max Timewarp (X2, X5, X10)\nImage format: JPEG/RAW\n\n\n\n‚úÖ Ensure reference scale object is in desired position.\n\nIt‚Äôs important to wait until GPS has acquired satellites so wait at least 30 seconds from turning the camera on before taking images.\nUsing a time delay (3-5 sec) can be handy to ensure you can trigger the shot and then have a few seconds to steady the camera before the shot is captured.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Field Collection"
    ]
  },
  {
    "objectID": "collect_field_collection.html#post-capture-procedures",
    "href": "collect_field_collection.html#post-capture-procedures",
    "title": "Field Collection",
    "section": "3. Post-Capture Procedures",
    "text": "3. Post-Capture Procedures\n‚úÖ Backup files to an external drive/laptop after fieldwork.\n‚úÖ Organize images into folders by date, location, or survey site.\n‚úÖ Charge batteries for use the following day.\n‚úÖ Clean and store camera equipment properly.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Field Collection"
    ]
  },
  {
    "objectID": "collect_insta_360.html",
    "href": "collect_insta_360.html",
    "title": "Insta 360 X4",
    "section": "",
    "text": "The insta 360 X4 is a great camera with 8K resolution. It does however lack an inbuilt GPS and therefore requires either a phone, GPS preview remote or an Apple watch to be of use for our workflow. This makes it a little more complex to setup and use. Nevertheless, we tested this and it works with the current stills image workflow. The interval mode can take an image every 3 seconds which is likely suitable for most survey methods.\n\nYou can find the scripts needed to use this camera here.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Field Collection",
      "Insta360 X4"
    ]
  },
  {
    "objectID": "collect_others.html",
    "href": "collect_others.html",
    "title": "Others",
    "section": "",
    "text": "There are several other 360 cameras soon to be released including the long awaited GoPro Max 2, rumored DJI Osmo 360 to name just a few. We will endeavour to assess and include them into the workflow if they turn out to be suitable.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Field Collection",
      "Other Cameras"
    ]
  },
  {
    "objectID": "collect_survey_design.html",
    "href": "collect_survey_design.html",
    "title": "Survey Design",
    "section": "",
    "text": "The camera technology and pannotator package are both highly flexible and can be used for capturing and analysing panospheric images in a virtually limitless number of applications.\nThis means that the way in which images are collected and used will vary widely. In an ecological study, for example, how you collect images might depend on the size of the organisms you are interested in (e.g., trees vs.¬†forbs), the location of target species (e.g., canopy vs.¬†ground-dwelling), the scale of processes or patterns of interest (individual plants to landscapes), habitat type (terrestrial, forested, or open habitats) and the timing of phenomena (e.g., rapid vs.¬†slow ecological change). Fundamentally, though, each study must consider the scale and timing of data collection and the quality of data to be extracted from the images. Here we describe some of these consideration by discussing a study in our accompanying Methods in Ecology & Evolution paper.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Survey Design"
    ]
  },
  {
    "objectID": "collect_survey_design.html#background",
    "href": "collect_survey_design.html#background",
    "title": "Survey Design",
    "section": "Background",
    "text": "Background\nIn 2017-2020 a very severe drought occurred in central and eastern Australia, and our project involved quantifying dieback of native plants on both small spatial scales (e.g., patches and sand dunes) and across the whole 2,000 km2 study region near Uluru in the Northern Territory. The challenge was to capture enough information on individual plants across multiple environments to enable us to generate accurate landscape-level dieback maps for different vegetation types and species. Fortunately, 360-degree cameras enable you to collect vast numbers of images at both small and large scales extremely easily.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Survey Design"
    ]
  },
  {
    "objectID": "collect_survey_design.html#data-collection",
    "href": "collect_survey_design.html#data-collection",
    "title": "Survey Design",
    "section": "Data collection",
    "text": "Data collection\nThere are 2 main sampling types particularly suited to this workflow:\n\nPlot-based (quadrat) sampling for local or small scale phenomena. A quadrat is often a square or circle placed on the ground for identifying and/or counting target organisms (e.g., cover, individual plants). Quadrats allow for precise estimates of variables such as population density, species richness, and coverage within a defined area.\nTransect sampling to capture large-scale variation in landforms and vegetation (e.g., dune-swale transitions, major soil and vegetation types). Transects can be either straight lines or any other shape desired.¬† They are excellent for detecting how a target variable such as species composition changes along environmental or spatial gradients.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Survey Design"
    ]
  },
  {
    "objectID": "collect_survey_design.html#merging-techniques",
    "href": "collect_survey_design.html#merging-techniques",
    "title": "Survey Design",
    "section": "Merging Techniques",
    "text": "Merging Techniques\nIn our study we walked 4km long transects laid out across the whole study region and collected images along the entire length of each. By adding plot overlays we were able to extract data from each image, providing detailed information on local to regional dieback patterns. Our transects were laid out in squares for 1) efficiency in collecting data (beginning and ending at the same point), and 2) to capture irregular landscape features (e.g., sand dunes, creeks).",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Survey Design"
    ]
  },
  {
    "objectID": "collect_survey_design.html#reference-scale",
    "href": "collect_survey_design.html#reference-scale",
    "title": "Survey Design",
    "section": "Reference Scale",
    "text": "Reference Scale\nOften you will want to quantify aspects of your target organism, such as plant size, which will involve knowing how far it is from the camera or taking measurements from associated images. The workflow facilitates this by allowing you to add overlays to the collected images before annotation and by capturing a reference scale object within each image. We found that a simple pole marked with metre increments for vertical measurement and a similarly marked rope on the ground for horizontal measurements are simple and effective tools for this purpose. It is important to place reference objects in a consistent way in the captured images (e.g., 5 metres from the camera) and collecting data with 2 people, one holding the camera and the other with the scaled reference object works very well. If you are measuring trees for example the person holding the pole could place the pole against the tree trunk and then the camera can be positioned any distance from the tree. To quickly mark out distances from the camera while capturing video we found it useful to have the second person walking ahead of the camera dragging a rope knotted at 1 metre increments.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Survey Design"
    ]
  },
  {
    "objectID": "collect_survey_design.html#data-verification",
    "href": "collect_survey_design.html#data-verification",
    "title": "Survey Design",
    "section": "Data Verification",
    "text": "Data Verification\nFor accurate and reliable data collection it is critical to collect reference data in the field from verification plots or points that can then be compared to the scored data from collected images. This ensures you can account for any biases or missed observations in a systematic repeatable way.\nYou can fine more information on data verification here.",
    "crumbs": [
      "Why",
      "How",
      "Collect",
      "Survey Design"
    ]
  },
  {
    "objectID": "examples/analyse/index.html",
    "href": "examples/analyse/index.html",
    "title": "Analyse Examples",
    "section": "",
    "text": "Pannotator Examples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "how.html",
    "href": "how.html",
    "title": "How",
    "section": "",
    "text": "There are three steps in the workflow: 1) collect your data using a 360-degree camera, 2) visualise and extract data from the images using the pannotator package, and 3) analyse the geocoded annotations. Open-source code for each of these steps is provided in the pannotator repositories.",
    "crumbs": [
      "Why",
      "How"
    ]
  },
  {
    "objectID": "use_cases.html",
    "href": "use_cases.html",
    "title": "Use Cases",
    "section": "",
    "text": "The workflow is highly customisable and can be applied to many different use cases. Here are just a few:",
    "crumbs": [
      "Why",
      "Use Cases"
    ]
  },
  {
    "objectID": "use_cases.html#weed-mapping",
    "href": "use_cases.html#weed-mapping",
    "title": "Use Cases",
    "section": "Weed mapping",
    "text": "Weed mapping\n\n\nMapping the distribution of weeds across landscapes often requires detailed information on the identity and abundance of weed species in local or small patches which can then be scaled up using predictive models based on satellite imagery.",
    "crumbs": [
      "Why",
      "Use Cases"
    ]
  },
  {
    "objectID": "use_cases.html#object-detection",
    "href": "use_cases.html#object-detection",
    "title": "Use Cases",
    "section": "Object detection",
    "text": "Object detection\n\n\n\n\n\n\n\n\n\nThe pannotator package allows the user to locate things of interest in panoramic images, then generate and export cropped images. These can be used to train object detection AI models. In this example we use the package to generate cropped images of different trees.",
    "crumbs": [
      "Why",
      "Use Cases"
    ]
  },
  {
    "objectID": "use_cases.html#community-ecology",
    "href": "use_cases.html#community-ecology",
    "title": "Use Cases",
    "section": "Community ecology",
    "text": "Community ecology\n\n\nModern 360-degree cameras allow users to capture vast numbers of high-resolution images as they traverse the landscape. Different plant species can be identified in panoramic images, annotated using drop-down menus in the pannotator package, and then mapped.",
    "crumbs": [
      "Why",
      "Use Cases"
    ]
  },
  {
    "objectID": "use_cases.html#demography",
    "href": "use_cases.html#demography",
    "title": "Use Cases",
    "section": "Demography",
    "text": "Demography\n\n\n\n\n\n\n\n\n\nIndividual plant sizes can be determined using the pannotator package by overlaying visual scales onto panoramic images or by including scales in the original photo or video. This graph shows the sizes of spinifex grass tussocks in an Australian outback landscape.",
    "crumbs": [
      "Why",
      "Use Cases"
    ]
  },
  {
    "objectID": "use_cases.html#tree-health",
    "href": "use_cases.html#tree-health",
    "title": "Use Cases",
    "section": "Tree health",
    "text": "Tree health\n\n\nAs climate change and droughts increasingly affect ecosystems around the world, many species are showing signs of stress or death in affected habitats. The pannotator package allows users to view images of trees or other plants from multiple perspectives and score their health. You can also crop and export individual trees and use these as examples to develop detailed scoring systems.",
    "crumbs": [
      "Why",
      "Use Cases"
    ]
  },
  {
    "objectID": "use_cases.html#canopy-studies",
    "href": "use_cases.html#canopy-studies",
    "title": "Use Cases",
    "section": "Canopy studies",
    "text": "Canopy studies\n\n\n\n\n\n\n\n\n\nDrones can be used to collect high resolution images of forest canopies for studying and mapping tree health, wildlife habitat, and many other variables of interest. You can use the pannotator package to extract and export geospatial data from panospheric drone images using customisable dropdown menus.",
    "crumbs": [
      "Why",
      "Use Cases"
    ]
  },
  {
    "objectID": "examples/collect/data_processing/add_overlays.html",
    "href": "examples/collect/data_processing/add_overlays.html",
    "title": "5 Add overlays to images",
    "section": "",
    "text": "The code below goes through an images folder and adds an overlay file to them. This overlay must be specific to the camera used to create the 360 degree images as the focal length of the lens etc. will define how the overlay should look.\nThe overlay was created using inkscape and then exported as a portable network graphics (.png) file with transparency. See the example below:\n\n\n\noverlay image with transparency"
  },
  {
    "objectID": "examples/collect/data_processing/add_overlays.html#add-overlays-to-the-images",
    "href": "examples/collect/data_processing/add_overlays.html#add-overlays-to-the-images",
    "title": "5 Add overlays to images",
    "section": "",
    "text": "The code below goes through an images folder and adds an overlay file to them. This overlay must be specific to the camera used to create the 360 degree images as the focal length of the lens etc. will define how the overlay should look.\nThe overlay was created using inkscape and then exported as a portable network graphics (.png) file with transparency. See the example below:\n\n\n\noverlay image with transparency"
  },
  {
    "objectID": "examples/collect/data_processing/add_overlays.html#code-to-create-overlays-magick-version",
    "href": "examples/collect/data_processing/add_overlays.html#code-to-create-overlays-magick-version",
    "title": "5 Add overlays to images",
    "section": "Code to Create Overlays (magick version)",
    "text": "Code to Create Overlays (magick version)\nThe code below uses imagemagick to load the underlying base file and then overlays the .png and saves out the flattened file for use in the kml/kmz files in the following steps.\n\nlibrary(magick)\nlibrary(tools)\nlibrary(magrittr)\n\n# you will need to edit the directory that contains the .jpg files to rename.\ndirectory &lt;- \"c:/path_to_the_directory_with_files_to_rename\"\n\n# set add overlays to TRUE\naddOverlays &lt;- TRUE\n\n# set the path to the overlay file (.png file with transparency)\noverlayImageFile &lt;- \"c:/path_to_overlay_file\"\n\nif (addOverlays == TRUE) {\n  overlay_file &lt;- overlayImageFile\n  \n  new_directory &lt;-  paste0(directory,\n                           \"_\",\n                           metresBetweenEachImageWanted,\n                           \"m_apart\")\n  \n  if (!dir.exists(paste0(new_directory))) {\n    print(paste0(new_directory, \" does not exist!\"))\n  stop(\"Did you run the code chunk above to find images a certain distance apart?\"\n  )\n}\n  # first create a new directory to add the overlay images to\n  dir.create(paste0(new_directory, \"/with_overlay/\"))\n  \n  file_extension &lt;- \"\\\\.[Jj][Pp][Gg]$\"\n  \n  files_lst &lt;-\n    list.files(\n      new_directory,\n      pattern = paste0(file_extension),\n      all.files = FALSE,\n      full.names = TRUE,\n      recursive = FALSE,\n      include.dirs = FALSE\n    )\n  \n  for (t in 1:length(files_lst)) {\n    background_image &lt;- magick::image_read(files_lst[t])\n    overlay &lt;-\n      magick::image_read(overlay_file)\n    image_dir &lt;- dirname(files_lst[t])\n    overlay_image_dir &lt;- paste0(image_dir, \"/with_overlay/\")\n    new_filename &lt;-\n      paste0(overlay_image_dir,\n             basename(tools::file_path_sans_ext(files_lst[t])),\n             \"_with_overlay.jpg\")\n    print(paste0(\"Adding overlay to create: \", new_filename))\n    img &lt;- c(background_image, overlay) %&gt;%\n      magick::image_flatten(.) %&gt;%\n      magick::image_write(., new_filename, format = \"jpg\")\n  }\n  \n} else {\n  print(\"'addOverlays' not TRUE: No overlay files generated\")\n}"
  },
  {
    "objectID": "examples/collect/data_processing/renaming_files.html",
    "href": "examples/collect/data_processing/renaming_files.html",
    "title": "3 Renaming files",
    "section": "",
    "text": "By default most consumer cameras like the gopro max & DJI drones don‚Äôt allow the user to specify the file names they apply to images that they create.\nA typical file name follows the format GS__XXXX.JPG - where XXXX is a counter number of the images taken by the camera.\nTo address this issue and make it easier to manage the files for processing, this code pre-pends the date_time stamp to the beginning of the files in a given directory. It‚Äôs useful for organising files when doing field work, especially when using multiple cameras at the same time.\nThe output format is: YYYYMMDD_HHMMSS_FileName.ext\nNote: Gopro now have a custom firmware allowing you to set file names in the field; see this GoPro Labs link.\nThis code checks the file name length initially assuming that files names directly downloaded from the camera are 12 characters long. If the files used have longer file names they will not be renamed. This ensures they are only renamed once.\n\nlibrary(exiftoolr)\nlibrary(stringr)\nlibrary(tools)\n\n# you will need to edit the directory that contains the .jpg files to rename.\ndirectory &lt;- \"c:/path_to_the_directory_with_files_to_rename\"\n\n# filter only .jpg or .JPG files\nfile_extension &lt;- \"\\\\.[Jj][Pp][Gg]$\"\n\nmy_files &lt;-\n  list.files(\n    directory,\n    pattern = paste0(\"*\", file_extension),\n    all.files = FALSE,\n    full.names = TRUE\n  )\n\n#read the exif information in the file to get the creation date\nfiles_df &lt;- exiftoolr::exif_read(my_files, args = c(\"-G1\", \"-a\", \"-s\"))\n\n#Loop through the files and check to change file names\n#this checks if the files have already been changed by looking at the length of the file name.\nfor (i in 1:nrow(files_df)) {\n  print(\"Checking if camera file name has not been changed\")\n  if (nchar(files_df[i, \"System:FileName\"]) == 12) {\n    print(\"File appears to be 12 characters long\")\n    print(paste0(\"SourceFile: \", files_df[i, \"SourceFile\"]))\n    origFullFileName &lt;- paste0(files_df[i, \"SourceFile\"])\n    createDate &lt;- paste0(files_df[i, \"ExifIFD:DateTimeOriginal\"])\n    print(paste0(\"CreateDate: \", createDate))\n    formattedCreateDate &lt;- stringr::str_replace_all(createDate, \":\", \"\")\n    formattedCreateDate &lt;- stringr::str_replace_all(formattedCreateDate, \" \", \"_\")\n    print(paste0(\"formattedCreateDate: \", formattedCreateDate))\n    file_ext &lt;- tolower(tools::file_ext(files_df[i, \"System:FileName\"]))\n    newFileName &lt;- paste0(files_df[i, \"System:Directory\"], \"/\", formattedCreateDate,\"_\",tools::file_path_sans_ext(basename(files_df[i, \"System:FileName\"])), \".\",file_ext)\n    print(paste0(\"newFileName: \", newFileName))\n    file.rename(from = origFullFileName, to = newFileName)\n    print(\"File name changed\")\n  } else {\n    print(\n      \"It appears that the file has already been renamed as it's greater than 12 characters long\"\n    )\n    print(paste0(\"SourceFile: \", files_df[i, \"SourceFile\"]))\n  }\n  \n}"
  },
  {
    "objectID": "examples/collect/generate_kmz/create_google_earth_files.html",
    "href": "examples/collect/generate_kmz/create_google_earth_files.html",
    "title": "6 Create google earth files",
    "section": "",
    "text": "This code generates a google earth kml file linking to the image files in the folder generated above. It uses ExifTool with a template ‚Äúkml_hide_rollover.fmt‚Äù to create the kml file.\n\nlibrary(readr)\n\n# you will need to edit the directory that contains the .jpg files to rename.\ndirectory &lt;- \"c:/path_to_the_directory_with_files_to_rename\"\n\n# set add overlays to TRUE\naddOverlays &lt;- TRUE\n\n# set the metres between each image\nmetresBetweenEachImageWanted &lt;- 50\n\nif (addOverlays == TRUE) {\n\nnew_directory &lt;-\n  paste0(directory,\n         \"_\",metresBetweenEachImageWanted,\n         \"m_apart/with_overlay\")\n\noutput_kml &lt;-\n   normalizePath(paste0(directory,\n         \"_\",\n         metresBetweenEachImageWanted,\n         \"m_apart_with_overlay.kml\"), winslash = \"/\", mustWork = FALSE)\n} else if(addOverlays == FALSE || length(addOverlays) == 0) {\n  new_directory &lt;-\n  paste0(directory,\n         \"_\",\n         metresBetweenEachImageWanted,\n         \"m_apart\")\n\noutput_kml &lt;-\n  normalizePath(paste0(directory,\n         \"_\",\n         metresBetweenEachImageWanted,\n         \"m_apart.kml\"), winslash = \"/\", mustWork = FALSE)\n}\n\nexif_args &lt;- c(\"-p\", \"kml_hide_rollover.fmt\", \"-r\")\nexiftoolr::exif_call(\n  args = exif_args,\n  path = new_directory,\n  stdout = output_kml,\n  quiet = FALSE\n)\n\n# now fix the links to the images to make them relative.\nmystring &lt;- readr::read_file(output_kml)\npath_only &lt;- paste0(dirname(output_kml))\n# check if the folder is root of the drive\nif(nchar(path_only) == 3){\n  mystring2 &lt;- gsub(path_only, \"./\", mystring, fixed = T)\n} else {\n  mystring2 &lt;- gsub(path_only, \".\", mystring, fixed = T)\n}\n\n# Write the file out\nsink(paste0(output_kml))\n  writeLines(mystring2)\nsink()\n\nprint(paste0(\"generated kml file: \", output_kml))"
  },
  {
    "objectID": "examples/collect/generate_kmz/create_google_earth_files.html#generate-kml-file",
    "href": "examples/collect/generate_kmz/create_google_earth_files.html#generate-kml-file",
    "title": "6 Create google earth files",
    "section": "",
    "text": "This code generates a google earth kml file linking to the image files in the folder generated above. It uses ExifTool with a template ‚Äúkml_hide_rollover.fmt‚Äù to create the kml file.\n\nlibrary(readr)\n\n# you will need to edit the directory that contains the .jpg files to rename.\ndirectory &lt;- \"c:/path_to_the_directory_with_files_to_rename\"\n\n# set add overlays to TRUE\naddOverlays &lt;- TRUE\n\n# set the metres between each image\nmetresBetweenEachImageWanted &lt;- 50\n\nif (addOverlays == TRUE) {\n\nnew_directory &lt;-\n  paste0(directory,\n         \"_\",metresBetweenEachImageWanted,\n         \"m_apart/with_overlay\")\n\noutput_kml &lt;-\n   normalizePath(paste0(directory,\n         \"_\",\n         metresBetweenEachImageWanted,\n         \"m_apart_with_overlay.kml\"), winslash = \"/\", mustWork = FALSE)\n} else if(addOverlays == FALSE || length(addOverlays) == 0) {\n  new_directory &lt;-\n  paste0(directory,\n         \"_\",\n         metresBetweenEachImageWanted,\n         \"m_apart\")\n\noutput_kml &lt;-\n  normalizePath(paste0(directory,\n         \"_\",\n         metresBetweenEachImageWanted,\n         \"m_apart.kml\"), winslash = \"/\", mustWork = FALSE)\n}\n\nexif_args &lt;- c(\"-p\", \"kml_hide_rollover.fmt\", \"-r\")\nexiftoolr::exif_call(\n  args = exif_args,\n  path = new_directory,\n  stdout = output_kml,\n  quiet = FALSE\n)\n\n# now fix the links to the images to make them relative.\nmystring &lt;- readr::read_file(output_kml)\npath_only &lt;- paste0(dirname(output_kml))\n# check if the folder is root of the drive\nif(nchar(path_only) == 3){\n  mystring2 &lt;- gsub(path_only, \"./\", mystring, fixed = T)\n} else {\n  mystring2 &lt;- gsub(path_only, \".\", mystring, fixed = T)\n}\n\n# Write the file out\nsink(paste0(output_kml))\n  writeLines(mystring2)\nsink()\n\nprint(paste0(\"generated kml file: \", output_kml))"
  },
  {
    "objectID": "examples/collect/generate_kmz/create_google_earth_files.html#convert-kml-images-into-a-kmz-file",
    "href": "examples/collect/generate_kmz/create_google_earth_files.html#convert-kml-images-into-a-kmz-file",
    "title": "6 Create google earth files",
    "section": "Convert kml & Images into a kmz File",
    "text": "Convert kml & Images into a kmz File\nThis code reads the .kml file created above and converts it to a .kmz file. This involves zipping up the images and the .kml file into one file. It also edits the relative links etc. The convenience of the kmz file is that it combines the kml and associated images into one file.\nNOTE: This code can generate kmz files &gt;2GB. These files won‚Äôt open correctly in google earth but are not corrupt and will work fine in pannotator. This is a limitation of google earth being 32 bit. You can read about it here.\n\nlibrary(fs)\nlibrary(usefun)\nlibrary(readr)\nlibrary(stringr)\nlibrary(zip)\n\n# Check if 'Set User Options' has been run and throw an error if not\ncheckUserOptionsExist(directory, metresBetweenEachImageWanted, addOverlays, overlayImageFile)\n\nif (addOverlays == TRUE) {\n\nnew_directory &lt;-\n  paste0(directory,\n         \"_\",\n         metresBetweenEachImageWanted,\n         \"m_apart/with_overlay\")\n\noutput_kml &lt;-\n  normalizePath(paste0(directory,\n         \"_\",\n         metresBetweenEachImageWanted,\n         \"m_apart_with_overlay.kml\"), winslash = \"/\", mustWork = FALSE)\n} else if(addOverlays == FALSE || length(addOverlays) == 0) {\n  new_directory &lt;-\n  paste0(directory,\n         \"_\",\n         metresBetweenEachImageWanted,\n         \"m_apart\")\n\noutput_kml &lt;-\n  normalizePath(paste0(directory,\n         \"_\",\n         metresBetweenEachImageWanted,\n         \"m_apart.kml\"), winslash = \"/\", mustWork = FALSE)\n}\n\nprint(\"Generating kmz file for:\")\nprint(output_kml)\n\nkml_file_name &lt;- basename(output_kml)\nkml_image_directory &lt;- new_directory\n\ndir_to_copy &lt;- normalizePath(kml_image_directory, winslash = \"/\", mustWork = FALSE)\ntemp_folder &lt;- paste0(usefun::get_parent_dir(directory), \"/temp\")\nnew_dir_path &lt;- normalizePath(paste0(temp_folder, \"/files/\"), winslash = \"/\", mustWork = FALSE)\n\nfs::dir_copy(dir_to_copy, new_dir_path, overwrite = TRUE)\nfs::file_copy(output_kml, temp_folder, overwrite = TRUE)\nfile.rename(\n  from = file.path(temp_folder, kml_file_name),\n  to = file.path(temp_folder, \"doc.kml\")\n)\n\n#clean up all of the extra line breaks in the kml file\nmystring &lt;- readr::read_file(file.path(temp_folder, \"doc.kml\"))\nmystring2 &lt;- gsub('\\r\\r\\r\\r\\r\\n', '\\n', mystring, fixed = T)\nmystring3 &lt;- gsub('\\r\\r\\r\\r\\n', '\\n', mystring2, fixed = T)\nmystring4 &lt;- gsub('\\r\\r\\r\\n', '\\n', mystring3, fixed = T)\nmystring5 &lt;- gsub('\\r\\r\\n', '\\n', mystring4, fixed = T)\nmystring6 &lt;- gsub('\\n\\r\\n', ' ', mystring5, fixed = T)\n\n# Extract the part of the string after the last '/'\n\nif (addOverlays == TRUE) {\nlast_part_dir &lt;- tail(strsplit(dir_to_copy, \"/\")[[1]], 2)\nmykml &lt;-\n  stringr::str_replace_all(mystring6[1], paste0(\"src='./\", last_part_dir[1],\"/\", last_part_dir[2]), \"src='files\")\n}  else if(addOverlays == FALSE) {\n  last_part_dir &lt;- tail(strsplit(dir_to_copy, \"/\")[[1]], 2)\nmykml &lt;-\n  stringr::str_replace_all(mystring6[1], paste0(\"src='./\", last_part_dir[2]), \"src='files\")\n}\n\nmykml &lt;- stringr::str_replace_all(mykml[1], \"&lt;name&gt;./\", \"&lt;name&gt;\")\nsink(paste0(file.path(temp_folder, \"doc.kml\")))\nwriteLines(mykml)\nsink()\n\n# name for new kmz file\nkmz_file_name &lt;-\n  paste0(usefun::get_parent_dir(directory),\"/\",\n         basename(tools::file_path_sans_ext(output_kml)),\n         \".kmz\")\n\n# create the kmz file\nmyWd &lt;- normalizePath(temp_folder, winslash = \"/\", mustWork = FALSE)\nfiles_lst &lt;-\n  list.files(\n    path = temp_folder,\n    pattern = \"*.jpg|*.kml\",\n    all.files = FALSE,\n    full.names = FALSE,\n    recursive = TRUE,\n    ignore.case = FALSE,\n    include.dirs = FALSE\n  )\n\n# zip the file up\nzip::zip(\n  kmz_file_name,\n  files_lst,\n  recurse = FALSE,\n  compression_level = 9,\n  include_directories = TRUE,\n  root = myWd,\n  mode = \"mirror\"\n)\n\n# remove the temp folder and its contents\nunlink(temp_folder, recursive = TRUE)"
  }
]